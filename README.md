# üß† Jarvis Native Core (V1)

**Jarvis Native Core** est le "Cerveau" central de votre assistant domotique multimodal. Il s'agit d'un serveur WebSocket Python haute performance con√ßu pour orchestrer des conversations fluides et interrompables avec Google Gemini 2.0 Flash.

## ‚ú® Fonctionnalit√©s Cl√©s

*   **‚ö° Latence Ultra-Faible** : Communication WebSocket bidirectionnelle temps r√©el.
*   **üó£Ô∏è Pipeline Hybride** : Utilise **Gemini 2.0 Flash** pour l'intelligence (Texte) et **Google Cloud TTS (Neural2)** pour une voix fran√ßaise naturelle et expressive ("Chirp 3 HD").
*   **‚úã Interruption Naturelle ("Barge-in")** : Syst√®me VAD (Search Activity Detection) local permettant de couper la parole √† l'assistant instantan√©ment en parlant, sans latence serveur.
*   **üé≠ Personnalit√© Configurable** : Prompt syst√®me ajustable via `.env` pour d√©finir le ton (actuellement "Complice & Taquine").

## üèóÔ∏è Architecture (V1)

Le syst√®me repose sur une boucle asynchrone d√©coupl√©e pour maximiser la r√©activit√©.

```mermaid
sequenceDiagram
    participant User as üë§ Utilisateur (Micro)
    participant Client as üíª Client Python (Audio Loop)
    participant Server as üöÄ Serveur FastAPI
    participant Gemini as ‚ú® Gemini 2.0 Flash (API)
    participant TTS as üó£Ô∏è Google TTS (Neural2)

    Note over User, Client: Flux Audio Continu

    par Audio Stream
        User->>Client: Parle (PCM 16kHz)
        Client->>Server: Envoie Audio (WebSocket Bytes)
        Server->>Gemini: Stream Audio (Live API)
    and Interruption Logic (Local VAD)
        Client->>Client: Analyse Volume (RMS)
        opt Volume > Seuil
            Client->>-Server:  {"type": "interrupt"} (JSON)
            Server->>Server: üî¥ STOP TTS & Clear Buffers
        end
    end

    Gemini-->>Server: R√©ponse (Texte Stream)
    
    loop TTS Processing
        Server->>Server: Bufferisation Phrases
        Server->>TTS: Synth√®se Texte -> Audio
        TTS-->>Server: Audio (MP3/PCM)
        
        opt Pas d'interruption
            Server-->>Client: Envoie Audio (WebSocket Bytes)
            Client->>User: Joue Audio (Haut-parleur)
        end
    end
```

### Explication du Flux
1.  **Client (Micro)** : Capture le son et l'envoie en continu au serveur.
    *   *Local VAD* : Si le client d√©tecte que vous parlez (volume √©lev√©), il envoie imm√©diatement un signal `"interrupt"` pour couper la r√©ponse en cours.
2.  **Serveur (Cerveau)** :
    *   Transmet l'audio utilisateur √† Gemini.
    *   Re√ßoit la r√©ponse de Gemini sour forme de **Texte**.
    *   Envoie le texte au service **TTS** pour g√©n√©rer l'audio (Voix "Despina").
    *   G√®re une queue prioritaire : si un signal "interrupt" arrive, tout le texte et l'audio en attente sont purg√©s.
3.  **Client (Speaker)** : Re√ßoit l'audio et le joue.

## üöÄ Installation & D√©marrage

### Pr√©-requis
*   Python 3.10+
*   Compte Google Cloud avec **Vertex AI** et **Text-to-Speech** activ√©s.
*   Cl√© d'API ou `gcloud auth application-default login`.

### Configuration (.env)
Cr√©ez un fichier `.env` √† la racine :
```ini
PROJECT_ID=votre-projet-gcp
LOCATION=us-central1
TTS_VOICE_NAME=fr-FR-Chirp3-HD-Despina
SYSTEM_INSTRUCTION="Tu es Jarvis, une assistante..."
```

### Lancement

1.  **Lancer le Serveur** :
    ```bash
    .\venv\Scripts\python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
    ```
2.  **Lancer le Client (Test)** :
    ```bash
    .\venv\Scripts\python scripts/audio_loop.py
    ```

## üó∫Ô∏è Roadmap

### Phase 1: Le Cerveau (Core Backend) [COMPL√âT√â ‚úÖ]
- [x] Initialisation du serveur WebSocket FastAPI
- [x] Int√©gration Gemini 2.0 Flash (Live API)
- [x] Pipeline Hybride (Texte -> TTS Neural2)
- [x] Gestion de l'interruption (Local VAD & Server Signal)

### Phase 2: L'Oreille (Hardware & Speaker ID) [√Ä VENIR]
- [ ] Support d'un wakeword personalis√© (https://colab.research.google.com/drive/1q1oe2zOyZp7UsB3jJiQ1IFn8z5YfjwEb?usp=sharing#scrollTo=1cbqBebHXjFD)
- [ ] Support des clients ESP32 (Hardware)
- [ ] Module **Speaker Identification** (Savoir QUI parle)
- [ ] Gestion multi-room

### Phase 3: Les Mains (Tools & Home Assistant)
- [ ] Int√©gration Home Assistant (via Function Calling Gemini)
- [ ] Contr√¥le multim√©dia
- [ ] M√©moire √† long terme
